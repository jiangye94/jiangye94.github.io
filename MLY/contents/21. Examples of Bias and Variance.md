[返回目录](../MLY_index.html)

# 21. 偏差和方差的例子 Examples of Bias and Variance

2018-10-10

[TOC]

## 学习收获

> sh

内容



Consider our cat classification task. An “ideal” classifier (such as a human) might achieve nearly perfect performance in this task.

考虑我们的猫分类任务。 “理想”分类器（例如人类）可能在此任务中实现近乎完美的性能。

Suppose your algorithm performs as follows:

假设您的算法执行如下：

- Training error = 1%
- Dev error = 11%

What problem does it have? Applying the definitions from the previous chapter, we estimate the bias as 1%, and the variance as 10% (=11%-1%). Thus, it has **high variance**. The classifier has very low training error, but it is failing to generalize to the dev set. This is also called **overfitting**.

它有什么问题？应用前一章的定义，我们估计偏差为1％，方差为10％（= 11％-1％）。因此，它具有很大的差异。分类器具有非常低的训练错误，但是它无法概括为开发组。这也称为过度拟合。

Now consider this:

现在考虑一下：

- Training error = 15%
- Dev error = 16%

We estimate the bias as 15%, and variance as 1%. This classifier is fitting the training set poorly with 15% error, but its error on the dev set is barely higher than the training error. This classifier therefore has **high bias**, but low variance. We say that this algorithm is **underfitting**.

我们估计偏差为15％，方差为1％。这个分类器对训练集的拟合很差，误差为15％，但它在开发集上的误差几乎不高于训练误差。因此，该分类器具有高偏差，但方差低。我们说这个算法是不合适的。

Now, consider this:

现在，考虑一下：

- Training error = 15%
- Dev error = 30%

We estimate the bias as 15%, and variance as 15%. This classifier has **high bias and high variance**: It is doing poorly on the training set, and therefore has high bias, and its performance on the dev set is even worse, so it also has high variance. The overfitting/underfitting terminology is hard to apply here since the classifier is simultaneously overfitting and underfitting.

我们估计偏差为15％，差异为15％。该分类器具有高偏差和高方差：它在训练集上表现不佳，因此具有高偏差，并且其在开发集上的性能更差，因此它也具有高方差。过度拟合/欠配合术语很难应用于此，因为分类器同时过度拟合和欠拟合。

Finally, consider this:

最后，考虑一下：

- Training error = 0.5%
- Dev error = 1%

This classifier is doing well, as it has low bias and low variance. Congratulations on achieving this great performance!

该分类器表现良好，因为它具有低偏差和低方差。恭喜您实现这一伟大的表现！