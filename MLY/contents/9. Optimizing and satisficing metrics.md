[返回目录](../MLY_index.html)

# 9. Optimizing and satisficing metrics

2018-10-07

[TOC]

## 学习收获

> sh

内容

Here’s another way to combine multiple evaluation metrics.

这是组合多个评估指标的另一种方法。

Suppose you care about both the accuracy and the running time of a learning algorithm. You need to choose from these three classifiers:

假设您关心学习算法的准确性和运行时间。您需要从以下三个分类器中进行选择：

| **Classifier** | **Accuracy** | **Running time** |
| -------------- | ------------ | ---------------- |
| **A**          | 90%          | 80ms             |
| **B**          | 92%          | 95ms             |
| **C**          | 95%          | 1,500ms          |

It seems unnatural to derive a single metric by putting accuracy and running time into a single formula, such as:

通过将准确性和运行时间放入单个公式来推导单个度量似乎不自然，例如：

​		Accuracy - 0.5*RunningTime

Here’s what you can do instead: First, define what is an “acceptable” running time. Lets say anything that runs in 100ms is acceptable. Then, maximize accuracy, subject to your classifier meeting the running time criteria. Here, running time is a “satisficing metric”—your classifier just has to be “good enough” on this metric, in the sense that it should take at most 100ms. Accuracy is the “optimizing metric.”

以下是您可以做的事情：首先，定义什么是“可接受的”运行时间。让我们说任何在100毫秒运行的东西都是可以接受的。然后，根据您的分类器满足运行时间标准，最大限度地提高准确性。在这里，运行时间是一个“令人满意的指标” - 您的分类器必须在此指标上“足够好”，因为它应该最多需要100毫秒。准确性是“优化指标”。

If you are trading off N different criteria, such as binary file size of the model (which is important for mobile apps, since users don’t want to download large apps), running time, and accuracy, you might consider setting N-1 of the criteria as “satisficing” metrics. I.e., you simply require that they meet a certain value. Then define the final one as the “optimizing” metric. For example, set a threshold for what is acceptable for binary file size and running time, and try to optimize accuracy given those constraints.

如果您正在处理N个不同的标准，例如模型的二进制文件大小（这对于移动应用程序很重要，因为用户不想下载大型应用程序），运行时间和准确性，您可以考虑设置N-1标准为“令人满意”的指标。即，你只需要它们满足一定的价值。然后将最后一个定义为“优化”度量。例如，为二进制文件大小和运行时间可接受的值设置阈值，并尝试在给定这些约束的情况下优化准确性。

As a final example, suppose you are building a hardware device that uses a microphone to listen for the user saying a particular “wakeword,” that then causes the system to wake up. Examples include Amazon Echo listening for “Alexa”; Apple Siri listening for “Hey Siri”; Android listening for “Okay Google”; and Baidu apps listening for “Hello Baidu.” You care about both the false positive rate—the frequency with which the system wakes up even when no one said the wakeword—as well as the false negative rate—how often it fails to wake up when someone says the wakeword. One reasonable goal for the performance of this system is to minimize the false negative rate (optimizing metric), subject to there being no more than one false positive every 24 hours of operation (satisficing metric).

作为最后一个示例，假设您正在构建一个硬件设备，该设备使用麦克风来监听用户说出特定的“唤醒词”，然后唤醒系统。例子包括Amazon Echo收听“Alexa”; Apple Siri正在收听“Hey Siri”; Android正在收听“Okay Google”;和百度应用程序听“你好百度。”你关心的是误报率 - 系统醒来的频率，即使没有人说出唤醒词 - 以及假阴性率 - 它经常无法唤醒当有人说出唤醒词。该系统性能的一个合理目标是最小化假阴性率（优化度量），每24小时操作（满足度量）不超过一个误报。

Once your team is aligned on the evaluation metric to optimize, they will be able to make faster progress.

一旦您的团队与评估指标保持一致以进行优化，他们就能够更快地取得进展。