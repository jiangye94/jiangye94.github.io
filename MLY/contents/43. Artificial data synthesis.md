[返回目录](../MLY_index.html)

# 43. 人工数据合成 Artificial data synthesis

2018-10-13

[TOC]

## 学习收获

> sh

内容

Your speech system needs more data that sounds as if it were taken from within a car. Rather than collecting a lot of data while driving around, there might be an easier way to get this data: By artificially synthesizing it.

您的语音系统需要更多听起来像是从汽车内部获取的数据。不是在驾车时收集大量数据，而是可能有更简单的方法来获取这些数据：通过人工合成它。

Suppose you obtain a large quantity of car/road noise audio clips. You can download this data from several websites. Suppose you also have a large training set of people speaking in a quiet room. If you take an audio clip of a person speaking and “add” to that to an audio clip of car/road noise, you will obtain an audio clip that sounds as if that person was speaking in a noisy car. Using this process, you can “synthesize” huge amounts of data that sound as if it were collected inside a car.

假设您获得了大量的汽车/道路噪音音频剪辑。您可以从多个网站下载此数据。假设您还有一大群人在安静的房间里讲话。如果您将一个人的音频剪辑发送到汽车/道路噪音的音频剪辑并对其进行“添加”，您将获得一个听起来好像该人在嘈杂的汽车中说话的音频剪辑。使用此过程，您可以“合成”大量听起来像是在车内收集的数据。

More generally, there are several circumstances where artificial data synthesis allows you to create a huge dataset that reasonably matches the dev set. Let’s use the cat image detector as a second example. You notice that dev set images have much more motion blur because they tend to come from cellphone users who are moving their phone slightly while taking the picture. You can take non-blurry images from the training set of internet images, and add simulated motion blur to them, thus making them more similar to the dev set.

更一般地说，有几种情况下，人工数据合成允许您创建一个与开发集合理匹配的庞大数据集。让我们使用猫图像检测器作为第二个例子。您注意到开发设置图像具有更多的运动模糊，因为它们往往来自手机用户，他们在拍照时稍微移动手机。您可以从互联网图像的训练集中获取非模糊图像，并为其添加模拟运动模糊，从而使它们更类似于开发集。

Keep in mind that artificial data synthesis has its challenges: it is sometimes easier to create synthetic data that appears realistic to a person than it is to create data that appears realistic to a computer. For example, suppose you have 1,000 hours of speech training data, but only 1 hour of car noise. If you repeatedly use the same 1 hour of car noise with different portions from the original 1,000 hours of training data, you will end up with a synthetic dataset where the same car noise is repeated over and over. While a person listening to this audio probably would not be able to tell—all car noise sounds the same to most of us—it is possible that a learning algorithm would “overfit” to the 1 hour of car noise. Thus, it could generalize poorly to a new audio clip where the car noise happens to sound different.

请记住，人工数据合成有其挑战：有时创建对人而言真实的合成数据比创建对计算机显得逼真的数据更容易。例如，假设你有1000小时的语音训练数据，但只有1小时的汽车噪音。如果您使用与原始1,000小时训练数据不同的部分重复使用相同的1小时汽车噪音，您将得到一个合成数据集，其中反复重复相同的汽车噪音。虽然听这个音频的人可能无法告诉所有汽车噪音对我们大多数人来说都是一样的 - 但学习算法可能会“过度”到1小时的汽车噪音。因此，它可能很难概括为一个新的音频剪辑，其中汽车噪音听起来不同。

Alternatively, suppose you have 1,000 unique hours of car noise, but all of it was taken from just 10 different cars. In this case, it is possible for an algorithm to “overfit” to these 10 cars and perform poorly if tested on audio from a different car. Unfortunately, these problems can be hard to spot.

或者，假设您有1000小时的汽车噪音，但所有这些都是从10辆不同的汽车中获取的。在这种情况下，如果对来自不同汽车的音频进行测试，则算法可能“过度拟合”到这10辆汽车并且表现不佳。不幸的是，这些问题很难被发现。

![43_car](../assets/43_car.png) 

To take one more example, suppose you are building a computer vision system to recognize cars. Suppose you partner with a video gaming company, which has computer graphics models of several cars. To train your algorithm, you use the models to generate synthetic images of cars. Even if the synthesized images look very realistic, this approach (which has been independently proposed by many people) will probably not work well. The video game might have ~20 car designs in the entire video game. It is very expensive to build a 3D car model of a car; if you were playing the game, you probably wouldn’t notice that you’re seeing the same cars over and over, perhaps only painted differently. I.e., this data looks very realistic to you. But compared to the set of all cars out on roads—and therefore what you’re likely to see in the dev/test sets—this set of 20 synthesized cars captures only a minuscule fraction of the world’s distribution of cars. Thus if your 100,000 training examples all come from these 20 cars, your system will “overfit” to these 20 specific car designs, and it will fail to generalize well to dev/test sets that include other car designs.

再举一个例子，假设您正在构建一个识别汽车的计算机视觉系统。假设您与一家视频游戏公司合作，该公司拥有多辆汽车的计算机图形模型。要训练您的算法，您可以使用模型生成汽车的合成图像。即使合成图像看起来非常逼真，这种方法（许多人独立提出）也可能效果不佳。视频游戏可能在整个视频游戏中拥有约20个汽车设计。建造汽车的3D汽车模型非常昂贵;如果你正在玩这个游戏，你可能不会注意到你一遍又一遍地看到同样的汽车，也许只有不同的颜色。即，这些数据看起来非常逼真。但与道路上的所有汽车相比 - 因此你可能会在开发/测试装置中看到 - 这套20辆合成汽车只占世界汽车分布的一小部分。因此，如果您的100,000个训练样例都来自这20辆汽车，那么您的系统将“适应”这20个特定的汽车设计，并且它将无法很好地概括为包括其他汽车设计的开发/测试装置。

When synthesizing data, put some thought into whether you’re really synthesizing a representative set of examples. Try to avoid giving the synthesized data properties that makes it possible for a learning algorithm to distinguish synthesized from non-synthesized examples—such as if all the synthesized data comes from one of 20 car designs, or all the synthesized audio comes from only 1 hour of car noise. This advice can be hard to follow.

在合成数据时，要考虑一下你是否真的在合成一组有代表性的例子。尽量避免给出合成数据属性，使得学习算法可以区分合成示例和非合成示例 - 例如，所有合成数据是否来自20种汽车设计中的一种，或者所有合成音频仅来自1小时汽车噪音。这个建议很难遵循。

When working on data synthesis, my teams have sometimes taken weeks before we produced data with details that are close enough to the actual distribution for the synthesized data to have a significant effect. But if you are able to get the details right, you can suddenly access a far larger training set than before.

在进行数据合成时，我的团队有时需要花费数周时间才能生成数据，其中的详细信息足够接近合成数据的实际分布，从而产生显着效果。但是如果你能够正确地获得细节，你可以突然获得比以前更大的训练集。