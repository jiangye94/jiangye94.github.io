[返回目录](../MLY_index.html)

# 16. 清理错误标记的开发和测试集示例 Cleaning up mislabeled dev and test set examples

2018-10-09

[TOC]

## 学习收获

> sh

内容

 

During error analysis, you might notice that some examples in your dev set are mislabeled. When I say “mislabeled” here, I mean that the pictures were already mislabeled by a human labeler even before the algorithm encountered it. I.e., the class label in an example *(x,y)* has an incorrect value for *y*. For example, perhaps some pictures that are not cats are mislabeled as containing a cat, and vice versa. If you suspect the fraction of mislabeled images is significant, add a category to keep track of the fraction of examples mislabeled:

在错误分析期间，您可能会注意到开发集中的某些示例被错误标记。当我在这里说“错误标记”时，我的意思是即使在算法遇到它之前，图片也已被人类贴标机贴错了标签。即，示例（x，y）中的类标签对y的值不正确。例如，也许一些不是猫的图片被错误标记为包含猫，反之亦然。如果您怀疑错误标记图像的分数很重要，请添加一个类别以跟踪错误标记的示例部分：

| **Image**      | **Dog** | **Great cat** | **Blurry** | **Mislabeled** | **Comments**                      |
| -------------- | ------- | ------------- | ---------- | -------------- | --------------------------------- |
| **…**          |         |               |            |                |                                   |
| **98**         |         |               |            | ✔              | Labeler missed cat in background  |
| **99**         |         | ✔             |            |                |                                   |
| **100**        |         |               |            | ✔              | Drawing of a cat; not a real cat. |
| **% of total** | 8%      | 43%           | 61%        | 6%             |                                   |

Should you correct the labels in your dev set? Remember that the goal of the dev set is to help you quickly evaluate algorithms so that you can tell if Algorithm A or B is better. If the fraction of the dev set that is mislabeled impedes your ability to make these judgments, then it is worth spending time to fix the mislabeled dev set labels.

你应该更正开发套装中的标签吗？请记住，开发集的目标是帮助您快速评估算法，以便您可以判断算法A或B是否更好。如果设置错误标记的开发部分阻碍了您做出这些判断的能力，那么值得花时间修复错误标记的设置标签。

For example, suppose your classifier’s performance is:

例如，假设您的分类器的性能是：

- Overall accuracy on dev set.………………. 90% (10% overall error.)

  开发设置的总体准确度.................. 90％（总体错误率为10％）

- Errors due to mislabeled examples..…. 0.6% (6% of dev set errors.)

  错误标记的例子引起的错误...... 0.6％（开发设置错误的6％）

- Errors due to other causes………………… 9.4% (94% of dev set errors)

  由于其他原因导致的错误..................... 9.4％（开发设置错误的94％）

Here, the 0.6% inaccuracy due to mislabeling might not be significant enough relative to the 9.4% of errors you could be improving. There is no harm in manually fixing the mislabeled images in the dev set, but it is not crucial to do so: It might be fine not knowing whether your system has 10% or 9.4% overall error.

在这里，由于错误标记导致的0.6％不准确性可能不够显着，相对于您可能改进的9.4％的错误。手动修复设备中错误标记的图像没有什么害处，但这样做并不重要：可能没问题，您的系统是否有10％或9.4％的总体错误。

Suppose you keep improving the cat classifier and reach the following performance:

假设您不断改进cat分类器并达到以下性能：

- Overall accuracy on dev set.………………. 98.0% (2.0% overall error.)

  开发设置的总体准确度.................. 98.0％（总错误2.0％）

- Errors due to mislabeled examples……. 0.6%. (30% of dev set errors.)

  错误标记的例子引起的错误...... 0.6％。 （30％的开发设置错误。）

- Errors due to other causes………………… 1.4% (70% of dev set errors) 

  由于其他原因导致的错误..................... 1.4％（开发设置错误的70％）

30% of your errors are due to the mislabeled dev set images, adding significant error to your estimates of accuracy. It is now worthwhile to improve the quality of the labels in the dev set. Tackling the mislabeled examples will help you figure out if a classifier’s error is closer to 1.4% or 2%—a significant relative difference.

30％的错误是由于错误标记的开发设置图像造成的，这会对您的准确度估计值产生重大误差。现在值得提高开发组中标签的质量。处理错误标记的示例将帮助您确定分类器的误差是否接近1.4％或2％ - 显着的相对差异。

It is not uncommon to start off tolerating some mislabeled dev/test set examples, only later to change your mind as your system improves so that the fraction of mislabeled examples grows relative to the total set of errors.

开始容忍一些错误标记的开发/测试集示例并不常见，只是稍后在系统改进时改变主意，以便错误标记的示例的比例相对于总错误集增加。

The last chapter explained how you can improve error categories such as Dog, Great Cat and Blurry through algorithmic improvements. You have learned in this chapter that you can work on the Mislabeled category as well—through improving the data’s labels.

最后一章解释了如何通过算法改进来改进Dog，Great Cat和Blurry等错误类别。您已经在本章中了解到，您可以通过改进数据的标签来处理错误标记的类别。

Whatever process you apply to fixing dev set labels, remember to apply it to the test set labels too so that your dev and test sets continue to be drawn from the same distribution. Fixing your dev and test sets together would prevent the problem we discussed in Chapter 6, where your team optimizes for dev set performance only to realize later that they are being judged on a different criterion based on a different test set.

无论您应用什么过程来修复开发设置标签，请记住将其应用于测试集标签，以便继续从同一分布中抽取开发和测试集。将开发和测试集合在一起可以防止我们在第6章中讨论的问题，在第6章中，您的团队优化了开发设置性能，以便稍后意识到他们将根据不同的测试集进行不同的评估。

If you decide to improve the label quality, consider double-checking both the labels of examples that your system misclassified as well as labels of examples it correctly classified. It is possible that both the original label and your learning algorithm were wrong on an example. If you fix only the labels of examples that your system had misclassified, you might introduce bias into your evaluation. If you have 1,000 dev set examples, and if your classifier has 98.0% accuracy, it is easier to examine the 20 examples it misclassified than to examine all 980 examples classified correctly. Because it is easier in practice to check only the misclassified examples, bias does creep into some dev sets. This bias is acceptable if you are interested only in developing a product or application, but it would be a problem if you plan to use the result in an academic research paper or need a completely unbiased measure of test set accuracy.

如果您决定提高标签质量，请考虑仔细检查系统错误分类的示例标签以及正确分类的示例标签。在一个例子中，原始标签和学习算法都可能是错误的。如果仅修复系统错误分类的示例标签，则可能会在评估中引入偏差。如果您有1,000个开发设置示例，并且如果您的分类器具有98.0％的准确度，则更容易检查错误分类的20个示例，而不是检查所有正确分类的980个示例。因为在实践中更容易检查错误分类的示例，所以偏差会蔓延到某些开发集中。如果您只对开发产品或应用程序感兴趣，这种偏见是可以接受的，但如果您计划在学术研究论文中使用结果或需要完全无偏见的测试集准确度测量，那么这将是一个问题。