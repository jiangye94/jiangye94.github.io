[返回目录](../MLY_index.html)

# 23. 解决偏见和差异 Addressing Bias and Variance

2018-10-10

[TOC]

## 学习收获

> sh

内容

 

Here is the simplest formula for addressing bias and variance issues: 

以下是解决偏差和方差问题的最简单公式：

- If you have high avoidable bias, increase the size of your model (for example, increase the size of your neural network by adding layers/neurons). 

  如果您有较高的可避免偏差，请增加模型的大小（例如，通过添加图层/神经元来增加神经网络的大小）。

- If you have high variance, add data to your training set. 

  如果您的方差很大，请将数据添加到训练集中。

If you are able to increase the neural network size and increase training data without limit, it is possible to do very well on many learning problems. 

如果您能够无限制地增加神经网络大小并增加训练数据，则可以在许多学习问题上做得很好。

In practice, increasing the size of your model will eventually cause you to run into computational problems because training very large models is slow. You might also exhaust your ability to acquire more training data. (Even on the internet, there is only a finite number of cat pictures!) 

实际上，增加模型的大小最终会导致计算问题，因为训练非常大的模型很慢。您也可能无法获得更多的培训数据。 （即使在互联网上，只有有限数量的猫图片！）

Different model architectures—for example, different neural network architectures—will have different amounts of bias/variance for your problem. A lot of recent deep learning research has developed many innovative model architectures. So if you are using neural networks, the academic literature can be a great source of inspiration. There are also many great open-source implementations on github. But the results of trying new architectures are less predictable than the simple formula of increasing the model size and adding data. 

不同的模型体系结构（例如，不同的神经网络体系结构）将针对您的问题具有不同的偏差/方差。最近的许多深度学习研究已经开发出许多创新的模型架构。因此，如果您使用神经网络，学术文献可以成为灵感的重要来源。 github上还有很多很棒的开源实现。但是，尝试新架构的结果比增加模型大小和添加数据的简单公式更难以预测。

Increasing the model size generally reduces bias, but it might also increase variance and the risk of overfitting. However, this overfitting problem usually arises only when you are not using regularization. If you include a well-designed regularization method, then you can usually safely increase the size of the model without increasing overfitting. 

增加模型尺寸通常会减少偏差，但也可能会增加方差和过度拟合的风险。但是，这种过度拟合问题通常仅在您不使用正则化时出现。如果您包含精心设计的正则化方法，那么通常可以安全地增加模型的大小而不会增加过度拟合。

Suppose you are applying deep learning, with L2 regularization or dropout, with the regularization parameter that performs best on the dev set. If you increase the model size, usually your performance will stay the same or improve; it is unlikely to worsen significantly. The only reason to avoid using a bigger model is the increased computational cost. 

假设您正在应用具有L2正则化或丢失的深度学习，其中正则化参数在开发集上表现最佳。如果您增加型号尺寸，通常您的性能将保持不变或改善;它不太可能显着恶化。避免使用更大模型的唯一原因是计算成本增加。