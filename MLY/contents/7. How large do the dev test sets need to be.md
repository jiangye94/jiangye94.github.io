[返回目录](../MLY_index.html)

# 7. 开发和测试集需要多大 How large do the dev/test sets need to be?

2018-10-07

[TOC]

## 学习收获

> 开发集，大到能够检测出算法之间的差异。
>
> 测试集，大到对系统的整体性能有高的置信度。
>
> 大数据时代，开发/测试集比例降低，但绝对数量增大。



The dev set should be large enough to detect differences between algorithms that you are trying out. For example, if classifier A has an accuracy of 90.0% and classifier B has an accuracy of 90.1%, then a dev set of 100 examples would not be able to detect this 0.1% difference. Compared to other machine learning problems I’ve seen, a 100 example dev set is small. Dev sets with sizes from 1,000 to 10,000 examples are common. With 10,000 examples, you will have a good chance of detecting an improvement of 0.1%.^2^

开发集应足够大，才能够检测出您正在尝试的算法之间的差异。例如，如果分类器A的准确度为90.0％，分类器B的准确度为90.1％，那么包含100个示例的开发集将无法检测到这0.1％的差异。与我见过的其他机器学习问题相比，100个示例的开发集是很小的。开发集的大小通常从1,000到10,000。对10,000个样本来说，您更有可能找到这0.1％，并改善它.^2^

For mature and important applications—for example, advertising, web search, and product recommendations—I have also seen teams that are highly motivated to eke out even a 0.01% improvement, since it has a direct impact on the company’s profits. In this case, the dev set could be much larger than 10,000, in order to detect even smaller improvements.

对于成熟和重要的应用程序来说 - 例如，广告、网页搜索和产品推荐 - 我也看到团队的积极地对这0.01％进行改进，因为它对公司的利润有直接影响。在这种情况下，开发集可能远大于10,000，就是为了检测甚至更小的改进。

How about the size of the test set? It should be large enough to give high confidence in the overall performance of your system. One popular heuristic had been to use 30% of your data for your test set. This works well when you have a modest number of examples—say 100 to 10,000 examples. But in the era of big data where we now have machine learning problems with sometimes more than a billion examples, the fraction of data allocated to dev/test sets has been shrinking, even as the absolute number of examples in the dev/test sets has been growing. There is no need to have excessively large dev/test sets beyond what is needed to evaluate the performance of your algorithms.

那测试集的应该多大呢？它应该足够大，大到对系统的整体性能有高的置信度。一种流行的启发式方法是将30％的数据用于测试集。当你有适当大小的样本时，这很好用 - 例如100到10,000个样本。但是在大数据时代，我们现在有可能超过十亿个样本的机器学习问题，分配给开发/测试集的数据的比例一直在缩小，即使开发/测试集中的样本的绝对数量一直在增长。除了评估算法性能所需的开发/测试集之外，不需要过多的开发/测试集。





---------

2 In theory, one could also test if a change to an algorithm makes a statistically significant difference on the dev set. In practice, most teams don’t bother with this (unless they are publishing academic research papers), and I usually do not find statistical significance tests useful for measuring interim progress.

2 理论上，人们还可以测试对算法的变化是否会对开发集产生统计上的显着差异。在实践中，大多数团队都不会为此烦恼（除非他们正在发表学术研究论文），而且我通常没有发现统计显着性测试对于衡量临时进度有用。