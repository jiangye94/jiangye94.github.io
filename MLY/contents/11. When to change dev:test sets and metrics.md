[返回目录](../MLY_index.html)

# 11. When to change dev/test sets and metrics

2018-10-07

[TOC]

## 学习收获

> sh

内容

When starting out on a new project, I try to quickly choose dev/test sets, since this gives the team a well-defined target to aim for.

在开始新项目时，我尝试快速选择开发/测试集，因为这为团队提供了明确定义的目标。

I typically ask my teams to come up with an initial dev/test set and an initial metric in less than one week—rarely longer. It is better to come up with something imperfect and get going quickly, rather than overthink this. But this one week timeline does not apply to mature applications. For example, anti-spam is a mature deep learning application. I have seen teams working on already-mature systems spend months to acquire even better dev/test sets.

我通常会要求我的团队在不到一周的时间内提出初始开发/测试集和初始指标 - 很少。最好是想出一些不完美的东西并快速前进，而不是过度思考。但这一周的时间表不适用于成熟的应用程序。例如，反垃圾邮件是一种成熟的深度学习应用程序。我已经看到在已经成熟的系统上工作的团队花费数月时间来获得更好的开发/测试集。

If you later realize that your initial dev/test set or metric missed the mark, by all means change them quickly. For example, if your dev set + metric ranks classifier A above classifier B, but your team thinks that classifier B is actually superior for your product, then this might be a sign that you need to change your dev/test sets or your evaluation metric.

如果您后来意识到您的初始开发/测试集或度量标准错过了标记，则无论如何都要快速更改它们。例如，如果您的开发设置+指标将分类器A排在分类器B之上，但您的团队认为分类器B实际上对您的产品更优越，那么这可能表示您需要更改您的开发/测试集或评估指标。

There are three main possible causes of the dev set/metric incorrectly rating classifier A higher:

设置/度量标准错误评级分类器A有三个主要可能原因：

1. <u>The actual distribution you need to do well on is different from the dev/test sets.</u>

   您需要做的实际分配与开发/测试集不同。

Suppose your initial dev/test set had mainly pictures of adult cats. You ship your cat app, and find that users are uploading a lot more kitten images than expected. So, the dev/test set distribution is not representative of the actual distribution you need to do well on. In this case, update your dev/test sets to be more representative.

假设您的初始开发/测试集主要是成年猫的图片。您运送您的猫应用程序，并发现用户正在上传比预期更多的小猫图像。因此，开发/测试集分布不能代表您需要做好的实际分布。在这种情况下，请更新您的开发/测试集以使其更具代表性。

  ![11_cat](../assets/11_cat.png)

2. <u>You have overfit to the dev set.</u>

   你对开发套装过度了。

The process of repeatedly evaluating ideas on the dev set causes your algorithm to gradually “overfit” to the dev set. When you are done developing, you will evaluate your system on the test set. If you find that your dev set performance is much better than your test set performance, it is a sign that you have overfit to the dev set. In this case, get a fresh dev set.

在开发集上重复评估想法的过程会导致您的算法逐渐“过度拟合”到开发集。完成开发后，您将在测试集上评估您的系统。如果您发现您的开发设置性能远远优于您的测试集性能，则表明您已经过度设置了开发设置。在这种情况下，获得一个新的开发设置。

If you need to track your team’s progress, you can also evaluate your system regularly—say once per week or once per month—on the test set. But do not use the test set to make any decisions regarding the algorithm, including whether to roll back to the previous week’s system. If you do so, you will start to overfit to the test set, and can no longer count on it to give a completely unbiased estimate of your system’s performance (which you would need if you’re publishing research papers, or perhaps using this metric to make important business decisions).

如果您需要跟踪团队的进度，您还可以定期评估您的系统 - 例如每周一次或每月一次 - 在测试集上。但是，不要使用测试集做出有关算法的任何决定，包括是否回滚到前一周的系统。如果你这样做，你将开始适应测试集，并且不再依赖它来对系统性能进行完全无偏见的估计（如果你发表研究论文，或者可能使用这个指标，你需要这样做）做出重要的商业决策）。

3. <u>The metric is measuring something other than what the project needs to optimize.</u>

   该指标衡量的是项目需要优化的内容。

Suppose that for your cat application, your metric is classification accuracy. This metric currently ranks classifier A as superior to classifier B. But suppose you try out both algorithms, and find classifier A is allowing occasional pornographic images to slip through. Even though classifier A is more accurate, the bad impression left by the occasional pornographic image means its performance is unacceptable. What do you do?

假设对于您的cat应用程序，您的度量标准是分类准确性。该度量当前将分类器A排序为优于分类器B.但是假设您尝试了两种算法，并且发现分类器A允许偶尔的色情图像滑过。即使分类器A更准确，偶尔的色情图片留下的坏印象也意味着它的表现是不可接受的。你是做什么？

Here, the metric is failing to identify the fact that Algorithm B is in fact better than Algorithm A for your product. So, you can no longer trust the metric to pick the best algorithm. It is time to change evaluation metrics. For example, you can change the metric to heavily penalize letting through pornographic images. I would strongly recommend picking a new metric and using the new metric to explicitly define a new goal for the team, rather than proceeding for too long without a trusted metric and reverting to manually choosing among classifiers.

在这里，度量标准未能确定算法B实际上比您的产品的算法A更好的事实。因此，您无法再信任该指标来选择最佳算法。是时候改变评估指标了。例如，您可以更改指标，严重惩罚通过色情图片。我强烈建议选择一个新指标并使用新指标明确定义团队的新目标，而不是在没有可信指标的情况下继续进行太长时间并且还原为在分类器之间手动选择。



It is quite common to change dev/test sets or evaluation metrics during a project. Having an initial dev/test set and metric helps you iterate quickly. If you ever find that the dev/test sets or metric are no longer pointing your team in the right direction, it’s not a big deal! Just change them and make sure your team knows about the new direction.

在项目期间更改开发/测试集或评估指标是很常见的。拥有初始开发/测试集和度量标准可帮助您快速迭代。如果您发现开发/测试集或指标不再指向您的团队正确的方向，那就没什么大不了的！只需更改它们，确保您的团队了解新方向。