[è¿”å›ç›®å½•](../MLY_index.html)

# 39. åŠ æƒæ•°æ® Weighting data

2018-10-13

[TOC]

## å­¦ä¹ æ”¶è·

> sh

å†…å®¹

Suppose you have 200,000 images from the internet and 5,000 images from your mobile app users. There is a 40:1 ratio between the size of these datasets. In theory, so long as you build a huge neural network and train it long enough on all 205,000 images, there is no harm in trying to make the algorithm do well on both internet images and mobile images.

å‡è®¾æ‚¨æœ‰æ¥è‡ªäº’è”ç½‘çš„200,000å¼ å›¾ç‰‡å’Œæ¥è‡ªæ‚¨çš„ç§»åŠ¨åº”ç”¨ç”¨æˆ·çš„5,000å¼ å›¾ç‰‡ã€‚è¿™äº›æ•°æ®é›†çš„å¤§å°ä¹‹é—´çš„æ¯”ç‡ä¸º40ï¼š1ã€‚ä»ç†è®ºä¸Šè®²ï¼Œåªè¦ä½ æ„å»ºä¸€ä¸ªå·¨å¤§çš„ç¥ç»ç½‘ç»œå¹¶åœ¨æ‰€æœ‰205,000ä¸ªå›¾åƒä¸Šè®­ç»ƒå®ƒè¶³å¤Ÿé•¿æ—¶é—´ï¼Œè¯•å›¾ä½¿ç®—æ³•åœ¨äº’è”ç½‘å›¾åƒå’Œç§»åŠ¨å›¾åƒä¸Šéƒ½èƒ½å¾ˆå¥½åœ°å®Œæˆå°±æ²¡æœ‰ä»»ä½•å®³å¤„ã€‚

But in practice, having 40x as many internet images as mobile app images might mean you need to spend 40x (or more) as much computational resources to model both, compared to if you trained on only the 5,000 images.

ä½†å®é™…ä¸Šï¼Œæ‹¥æœ‰40å€äºç§»åŠ¨åº”ç”¨å›¾ç‰‡çš„äº’è”ç½‘å›¾åƒå¯èƒ½æ„å‘³ç€æ‚¨éœ€è¦èŠ±è´¹40å€ï¼ˆæˆ–æ›´å¤šï¼‰çš„è®¡ç®—èµ„æºæ¥å¯¹ä¸¤è€…è¿›è¡Œå»ºæ¨¡ï¼Œç›¸æ¯”ä¹‹ä¸‹ï¼Œæ‚¨åªéœ€è¦è®­ç»ƒ5,000å¼ å›¾åƒã€‚

If you donâ€™t have huge computational resources, you could give the internet images a much lower weight as a compromise.

å¦‚æœæ‚¨æ²¡æœ‰åºå¤§çš„è®¡ç®—èµ„æºï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥å°†äº’è”ç½‘å›¾åƒä½œä¸ºæŠ˜è¡·æ–¹æ¡ˆç»™äºˆæ›´ä½çš„æƒé‡ã€‚

For example, suppose your optimization objective is squared error (This is not a good choice for a classification task, but it will simplify our explanation.) Thus, our learning algorithm tries to optimize:

ä¾‹å¦‚ï¼Œå‡è®¾æ‚¨çš„ä¼˜åŒ–ç›®æ ‡æ˜¯å¹³æ–¹è¯¯å·®ï¼ˆè¿™ä¸æ˜¯åˆ†ç±»ä»»åŠ¡çš„å¥½é€‰æ‹©ï¼Œä½†å®ƒå°†ç®€åŒ–æˆ‘ä»¬çš„è§£é‡Šã€‚ï¼‰å› æ­¤ï¼Œæˆ‘ä»¬çš„å­¦ä¹ ç®—æ³•å°è¯•ä¼˜åŒ–ï¼š

![39_formula1](../assets/39_formula1.png)  

The first sum above is over the 5,000 mobile images, and the second sum is over the 200,000 internet images. You can instead optimize with an additional parameter ğ›½:

ä¸Šé¢çš„ç¬¬ä¸€ç¬”é‡‘é¢è¶…è¿‡5,000å¼ ç§»åŠ¨å›¾åƒï¼Œç¬¬äºŒç¬”é‡‘é¢è¶…è¿‡200,000å¼ äº’è”ç½‘å›¾åƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨é™„åŠ å‚æ•°Î²è¿›è¡Œä¼˜åŒ–ï¼š

![39_formula2](../assets/39_formula2.png)  

If you set ğ›½=1/40, the algorithm would give equal weight to the 5,000 mobile images and the 200,000 internet images. You can also set the parameter ğ›½ to other values, perhaps by tuning to the dev set.

å¦‚æœè®¾ç½®Î²= 1/40ï¼Œç®—æ³•å°†ç»™äºˆ5,000ä¸ªç§»åŠ¨å›¾åƒå’Œ200,000ä¸ªäº’è”ç½‘å›¾åƒç›¸åŒçš„æƒé‡ã€‚æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡è°ƒæ•´åˆ°å¼€å‘é›†æ¥å°†å‚æ•°Î²è®¾ç½®ä¸ºå…¶ä»–å€¼ã€‚

By weighting the additional Internet images less, you donâ€™t have to build as massive a neural network to make sure the algorithm does well on both types of tasks. This type of re-weighting is needed only when you suspect the additional data (Internet Images) has a very different distribution than the dev/test set, or if the additional data is much larger than the data that came from the same distribution as the dev/test set (mobile images).

é€šè¿‡å‡å°‘é¢å¤–çš„äº’è”ç½‘å›¾åƒæƒé‡ï¼Œæ‚¨ä¸å¿…æ„å»ºåºå¤§çš„ç¥ç»ç½‘ç»œï¼Œä»¥ç¡®ä¿ç®—æ³•åœ¨ä¸¤ç§ç±»å‹çš„ä»»åŠ¡ä¸Šéƒ½èƒ½å¾ˆå¥½åœ°å®Œæˆã€‚åªæœ‰å½“æ‚¨æ€€ç–‘é™„åŠ æ•°æ®ï¼ˆInternetå›¾åƒï¼‰çš„åˆ†å¸ƒä¸å¼€å‘/æµ‹è¯•é›†çš„åˆ†å¸ƒéå¸¸ä¸åŒï¼Œæˆ–è€…é™„åŠ æ•°æ®è¿œè¿œå¤§äºæ¥è‡ªåŒä¸€åˆ†å‘çš„æ•°æ®æ—¶ï¼Œæ‰éœ€è¦è¿™ç§ç±»å‹çš„é‡æ–°åŠ æƒã€‚å¼€å‘/æµ‹è¯•é›†ï¼ˆç§»åŠ¨å›¾åƒï¼‰ã€‚