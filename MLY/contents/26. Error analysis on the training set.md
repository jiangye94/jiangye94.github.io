[返回目录](../MLY_index.html)

# 26. 训练集的误差分析 Error analysis on the training set

2018-10-10

[TOC]

## 学习收获

> sh

内容



Your algorithm must perform well on the training set before you can expect it to perform well on the dev/test sets.

您的算法必须在训练集上运行良好，才能期望它在开发/测试集上表现良好。

In addition to the techniques described earlier to address high bias, I sometimes also carry out an error analysis on the *training data*, following a protocol similar to error analysis on the Eyeball dev set. This can be useful if your algorithm has high bias—i.e., if it is not fitting the training set well.

除了前面描述的用于解决高偏差的技术之外，我有时还会根据类似于Eyeball开发套件的错误分析的协议对训练数据进行错误分析。如果您的算法具有高偏差，即如果它不能很好地拟合训练集，则这可能很有用。

For example, suppose you are building a speech recognition system for an app and have collected a training set of audio clips from volunteers. If your system is not doing well on the training set, you might consider listening to a set of ~100 examples that the algorithm is doing poorly on to understand the major categories of training set errors. Similar to the dev set error analysis, you can count the errors in different categories:

例如，假设您正在为应用程序构建语音识别系统，并从志愿者那里收集了一组音频剪辑。如果您的系统在训练集上表现不佳，您可能会考虑收听一组约100个算法，这些算法很难理解训练集错误的主要类别。与dev set error analysis类似，您可以计算不同类别的错误：

| **Audio clip** | **Loud background noise** | **User spoke quickly** | **Far from microphone** | **Comments**                      |
| -------------- | ------------------------- | ---------------------- | ----------------------- | --------------------------------- |
| **1**          | ✔                         |                        |                         | Car noise                         |
| **2**          | ✔                         |                        | ✔                       | Restaurant noise                  |
| **3**          |                           | ✔                      | ✔                       | User shouting across living room? |
| **4**          | ✔                         |                        |                         | Coffeeshop                        |
| **% of total** | 75%                       | 25%                    | 50%                     |                                   |

In this example, you might realize that your algorithm is having a particularly hard time with training examples that have a lot of background noise. Thus, you might focus on techniques that allow it to better fit training examples with background noise.

在此示例中，您可能会发现您的算法在使用具有大量背景噪音的训练示例时会遇到特别困难。因此，您可以专注于允许其更好地适应具有背景噪声的训练示例的技术。

You might also double-check whether it is possible for a person to transcribe these audio clips, given the same input audio as your learning algorithm. If there is so much background noise that it is simply impossible for anyone to make out what was said, then it might be unreasonable to expect any algorithm to correctly recognize such utterances. We will discuss the benefits of comparing your algorithm to human-level performance in a later section.

在给定与学习算法相同的输入音频的情况下，您还可以仔细检查一个人是否可以转录这些音频片段。如果有太多的背景噪音，任何人都无法弄清楚所说的内容，那么期望任何算法正确识别这些话语可能是不合理的。我们将在后面的部分讨论将算法与人类级别性能进行比较的好处。