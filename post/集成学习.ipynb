{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集成学习（python实现）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 介绍\n",
    "集成多个模型，普遍化和多样化，降低方差\n",
    "\n",
    "#### 基础基础方法\n",
    "* 最大投票法（Max Voting）\n",
    "* 平均（Averaging）法\n",
    "* 加权平均（Weighted Average）法\n",
    "\n",
    "#### 高级集成方法\n",
    "* 堆叠（Stacking）\n",
    "* 混合（Blending）\n",
    "* Bagging\n",
    "* 提升（Boosting）\n",
    "\n",
    "#### 基于Bagging和Boosting的算法\n",
    "\n",
    "* Bagging meta-estimator\n",
    "* 随机森林\n",
    "* AdaBoost\n",
    "* GBM\n",
    "* XGB\n",
    "* Light GBM\n",
    "* CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最大投票法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1=model1.predict(X_test)\n",
    "pred2=model2.predict(X_test)\n",
    "pred3=model3.predict(X_test)\n",
    "\n",
    "final_pred = np.array([])\n",
    "\n",
    "for i in range(0,len(X_test)):\n",
    "    final_pred =np.append(final_pred, mode([pred1[i], pred2[i], pred3[i]]))\n",
    "accuracy_score(final_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = DecisionTreeClassifier()\n",
    "\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('knn', model2),('dt', model3)], voting='hard')\n",
    "model.fit(X_train,y_train)\n",
    "final_pred = model.predict(X_test)\n",
    "# model.score(X_test,y_test)\n",
    "accuracy_score(final_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 平均法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1=model1.predict_proba(X_test)\n",
    "pred2=model2.predict_proba(X_test)\n",
    "pred3=model3.predict_proba(X_test)\n",
    "\n",
    "finalpred=(pred1+pred2+pred3)/3\n",
    "accuracy_score(np.argmax(finalpred, axis=1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(finalpred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加权平均法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1=model1.predict_proba(X_test)\n",
    "pred2=model2.predict_proba(X_test)\n",
    "pred3=model3.predict_proba(X_test)\n",
    "\n",
    "finalpred=(pred1*0.3+pred2*0.3+pred3*0.4)\n",
    "accuracy_score(np.argmax(finalpred, axis=1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(finalpred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高级集成方法\n",
    "#### 堆叠/Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Stacking(model, train, y, test, n_fold):\n",
    "    folds = StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "    test_pred = np.empty((test.shape[0],1),float)\n",
    "    train_pred = np.empty((0,1),float)\n",
    "\n",
    "    for train_indices, val_indices in folds.split(train,y):\n",
    "        X_train,X_val=train[train_indices],train[val_indices]\n",
    "        y_train,y_val=y[train_indices],y[val_indices]\n",
    "\n",
    "        model.fit(X=X_train,y=y_train)\n",
    "        train_pred=np.append(train_pred,model.predict(X_val))\n",
    "        test_pred=np.append(test_pred,model.predict(test))\n",
    "        \n",
    "    return test_pred.reshape(-1,1),train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.DataFrame(X_train)\n",
    "# y_train = pd.DataFrame(y_train)\n",
    "model1 = DecisionTreeClassifier(random_state=1)\n",
    "test_pred1, train_pred1=Stacking(model=model1,n_fold=10, train=X_train,test=X_test,y=y_train)\n",
    "train_pred1=pd.DataFrame(train_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1)\n",
    "\n",
    "model2 = KNeighborsClassifier()\n",
    "test_pred2, train_pred2=Stacking(model=model2,n_fold=10,train=X_train,test=X_test,y=y_train)\n",
    "\n",
    "train_pred2=pd.DataFrame(train_pred2)\n",
    "test_pred2=pd.DataFrame(test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 0,\n",
       "       1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2,\n",
       "       0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0,\n",
       "       0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0,\n",
       "       0, 2, 1, 0, 1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1,\n",
       "       1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0,\n",
       "       2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n",
       "       2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 2, 1, 1, 0, 1, 2,\n",
       "       1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0,\n",
       "       0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0,\n",
       "       0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2,\n",
       "       1, 0, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2,\n",
       "       0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 2, 1,\n",
       "       1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2,\n",
       "       2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 2, 1, 1, 0, 1, 2, 2, 1,\n",
       "       2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       1, 0, 0, 2, 1, 0, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1,\n",
       "       2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_pred1, train_pred2], axis=1)\n",
    "df_test = pd.concat([test_pred1, test_pred2], axis=1)\n",
    "\n",
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(df,y_train)\n",
    "model.predict(df_test)\n",
    "# model.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考来源：\n",
    "* http://url.cn/5LWIsw8\n",
    "* https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
